{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convergence as Entropy Minimization Across Lexico-Semantic Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Communication Accommodation Theory\n",
    "\n",
    "Lexical alignment/Convergence both describe the tendency for members of a group to converge on similar means of discussing a topic.\n",
    "\n",
    "Similar means can be expressed as a minimization in the entropy between utterances made by group members. As group members A and B sound more similar to one another, you can recover more of a group member A's semantic content from the lexical items in member B's message/utterance/sentence, because you can better predict member A's message just by listening to member B. In other words because they're using similar language to say the same thing the predictability of one utterance when presented with another utterance increases and thus entropy (i.e. how unpredictable two things are based on obersrvations of one or the other) decreases.\n",
    "\n",
    "Similarity in the precise lexico-semantic meaning of two words can be measured using contextual word embeddings. Models like BERT (and it's twin RoBERTa) provide contextually informed word embeddings.\n",
    "\n",
    "The following is a quick analysis attempting to recover Social Identity attributes for speakers based on imputed convergence with another group.\n",
    "\n",
    "Specifically: recovering political party affiliation from tweets discussing immigrants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Generating intial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from intergroupEntropy.data.redditany.redo_collection_corpus import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Word vector representations\n",
    "\n",
    "$$ E_{xi} = wv(i \\in x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'ssh -'\n",
    "'tmux attach-session -s BERT'\n",
    "'python3 ./reddit_vecs.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Probability based on word vectors\n",
    "\n",
    "Based on our understanding of how to test conceptual similarities between individuals' utterances and groups', and to get a grip on our BERT-based method, let's imagine that an interlocutor is playing a kind of language reconstruction game that is directly related to the question posed in our description of the Bernoulli process. The interlocutor is given a single utterance from an individual $x$, broken up into tokens $xi$. The interlocutor is then given a set of tokens $j$ from several utterances all taken from a number of members of some group--$y j$. The interlocutor is then asked to take the groups' tokens $yj$ and reconstruct an utterance that means something that is as similar as possible to the sentence $x$. If they can reconstruct a sentence from the groups' tokens $yj$ that means something similar to the utterance $x$, this would effectively answer the question of whether or not\n",
    "\"for each token ($xi$) in the sentence $x$, tell me if someone in the sample $y$ used the same word, or a synonym for it, in the same way that it was used in $x$.\"\n",
    "Furthermore, in this scenario, reconstructed utterances that are more similar in meaning to the original utterance will have lower entropy. Reconstructed utterances that are either less similar or less intelligible will have higher entropy.\n",
    "\n",
    "We start our language game by, first, converting all of the tokens in both $x$ and $y$ to BERT word vectors (Devlin et al. 2019. This will allow us to capture similarity between tokens that are semantically similar but are not a 1:1 mapping of the same word. Let $E_{xi}$ be the set of BERT word vectors for each token $i$ in a sentence $x$ and $E_{yj}$ be the set of BERT word vectors for each token $j$ in a sample $y$ of utterances from a group. The equation \\ref{eq:bert} below shows the process of converting tokens $i \\in x$ to word vectors. Tokens $j \\in y$ are converted to word vectors via the same process.\n",
    "\n",
    "$$E_{xi} = BERT(i \\in x)$$\n",
    "\n",
    "The utility of word vector models is that they represent the meaning of words spatially and, surprisingly, accurately. Even in early, contextually uninformed models, words that are semantically similar to one another based on their word vectors cluster closer together in word vector space (GLoVe: Pennington et al. 2014; Word2Vec: Mikolov et al. 2013; BERT: Devlin et al. 2019). In contextually aware models like BERT and all subsequent transformer models words that have similar word senses cluster separately from other word senses. This allows us to make fine grain distinctions between the different meanings of polysemous words like the many meanings of \"bank, but it also allows us to capture subtle community/group-specific differences in word usage like the differences in the use of the word \"slay\" in example \\ref{} (Devlin et al. 2019). In layman's terms, if a word vector represents the meaning of a word as a point in space, words that are more semantically related to one another will be closer to one another. And if those word vectors are generated by a contextually aware model the closer \\textit{the word senses} of two words are to one another the closer two word vectors will be to one another in vector space. A popular way to measure the proximity of two word vectors to one another is to use Cosine Error (CoE), where a CoE value of 0 indicates that the word vectors for two words in high dimensional space are in a superposition of one another, and 2 means that they are maximally divergent.\n",
    "\n",
    "Think of finding similar words in word vector space like a game of darts, where CoE values that are closer to 0 when comparing a word vector $E_{xi}$ to another word vector $E_{yj}$ indicate that if you threw a dart at $E_{xi}$ you are more likely to accidentally hit the word vector $E_{yj}$ if you miss.\n",
    "\n",
    "Please note however that \\textit{proximity} in vector space is different from a probability, and CoE values are just a scaled measurement of proximity, not the probability that two vectors are the same or similar. An additional step is needed to render CoE values as probabilities that can be used as part of a statistical framework. To convert CoE to a probability, we leverage a half-Gaussian distribution, continuous on an interval of 0 to infinity, with two parameters: (1) a location parameter $\\mu=0.0$ such that as the CoE value for the comparison of two word vectors approaches 0 we have maximum confidence that the two words mean the same thing, and (2) a scale parameter $\\sigma$ that sets a penalty weight for CoE values farther away from 0.\n",
    "$$P(E_{xi} | E_{yj}) = P_{\\mathcal{N}_{[0,\\infty]}}\\left( CoE(E_{xi},E_{yj}) \\bigg|  \\mu=0., \\sigma \\right)$$\n",
    "\n",
    "Think of $\\sigma$ like the accuracy of the dart thrower in our previous example, where lower $\\sigma$ values equate to the dart thrower only hitting a word/token $xi$ if it is very close to $yj$ in word vector space.\n",
    "\n",
    "However, we almost never have a reason to compare any one vector from a sentence $xi$ to every single vector from another sentence/distribution, $yj$. After all, the question we're trying to answer as described in the previous section is \"for each token ($xi$) in the sentence $x$, I want you to tell me if someone in the sample $y$ used the same word, or a synonym for it, in the same way that it was used in $x$.\" Based on this, it’s better to ask, instead how likely is a vector $xi$ might show up in any sample $y$ from the cummulative utterances for the group $Y$, conditioned on what we know about the composition of the sample $y$. To do this, we take the probability of a token $xi$ from the sentence $x$ and the token $yj$ from $y$ that has the lowest CoE with $xi$. This effectively replicates the hypothetical study participant in the example given at the top of this section selecting a word that most closely means the same thing as one of the words ($xi$) from the sentence $x$ and trying to use it to create a new utterance that closely matches $x$ in meaning. Furthermore, if nothing in the distribution $y$ is semantically similar, nor embedded in a similar context as $xi$ is in $x$, then the minimum CoE value will be high (and thus indicates that the token $xi$ doesn't have anything approximating a similar term or usage in $y$). We thus rewrite equation the last equation as follows:\n",
    "\n",
    "$$P(E_{xi} | E_{y}) = P_{\\mathcal{N}_{[0,\\infty]}} \\left( \\min_{j} \\left(CoE(E_{xi},E_{y}) \\right) \\bigg|  \\mu=0., \\sigma \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Entropy across sentences using probability based on their component word vectors\n",
    "\n",
    "Meanwhile, the probability that an individual's message $x$ exhibits convergence with the messaging habits of a groups can be calculated by finding the entropy for $x$ and an imputed sample from the group $y \\in \\lbrace Y | Y_g \\rbrace$.\n",
    "\n",
    "$$H( x ; y ) = -\\sum_i P(E_{xi}|E_{y}) \\log P(E_{xi}|E_{y})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'ssh -'\n",
    "'tmux attach-session -s BERT'\n",
    "'python3 ./indH.py'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Assessment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I loaded the data from the checkpoint described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from SIS.methods.reddit_feminism.stitch_data import get_stitched_data\n",
    "\n",
    "data_path = \"/Users/zacharyrosen/airlock/d/convergence/feminism-menslib-mensrights/women/summaries/menslib/2/posteriors-MensLib.pt\"\n",
    "ckpt = torch.load(data_path)\n",
    "\n",
    "total_H = ckpt['M']\n",
    "_ids = ckpt['labels']\n",
    "\n",
    "total_H = total_H.transpose(0,1).transpose(1,2)\n",
    "\n",
    "groups = ['Feminism', 'MensRights', 'MensLib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([463, 3, 200])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_H.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1 Assessing entropic differences per each sentence in the corpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind as ttest\n",
    "\n",
    "pvalue, statistic = [], []\n",
    "for i in range(total_H.shape[0]):\n",
    "    r = [\n",
    "        ttest(\n",
    "            total_H[i, 2][~total_H[i, 2].isnan()],\n",
    "            total_H[i, j][~total_H[i, j].isnan()]\n",
    "        ) for j in range(total_H.shape[1])]\n",
    "    pvalue += [np.array([ri.pvalue for ri in r])]\n",
    "    statistic += [np.array([ri.statistic for ri in r])]\n",
    "\n",
    "pvalue, statistic = np.array(pvalue), np.array(statistic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "minima = [\n",
    "    torch.cat(\n",
    "        [\n",
    "            total_H[i,j][~total_H[i,j].isnan()].mean(axis=-1).view(1,-1) for j in range(len(groups))\n",
    "        ],\n",
    "        dim=-1\n",
    "    ) for i in range(total_H.shape[0])\n",
    "]\n",
    "minima = torch.cat(minima, dim=0).argmin(dim=-1)\n",
    "\n",
    "pct_data, confusion_data, means_data = [], [], []\n",
    "\n",
    "for i, g in enumerate(groups):\n",
    "\n",
    "    p_res = (pvalue[:,i] < .025)\n",
    "    mu_res = (statistic[:,i] < 0)\n",
    "    res =  p_res & mu_res\n",
    "\n",
    "    pct_data += [res.mean(axis=0)]\n",
    "    confusion_data += [(p_res & (minima==i).numpy()).sum(axis=0)]\n",
    "    means_data += [mu_res.mean(axis=0)]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['cond'] = groups\n",
    "results['results'] = np.array(pct_data)\n",
    "\n",
    "mean_results = pd.DataFrame()\n",
    "mean_results['cond'] = groups\n",
    "mean_results['results'] = np.array(means_data)\n",
    "\n",
    "confusion = pd.DataFrame()\n",
    "confusion['cond'] = groups\n",
    "confusion['results'] = np.array(confusion_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To interpret the results, higher scores indicate that more examples from the condition in the row passed the test when comparing the reconstruction of terms from the same condition as the row to examples from the condition in the column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         cond   results\n0    Feminism  0.965443\n1  MensRights  0.969762\n2     MensLib  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cond</th>\n      <th>results</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Feminism</td>\n      <td>0.965443</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MensRights</td>\n      <td>0.969762</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MensLib</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "         cond   results\n0    Feminism  0.984881\n1  MensRights  0.978402\n2     MensLib  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cond</th>\n      <th>results</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Feminism</td>\n      <td>0.984881</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MensRights</td>\n      <td>0.978402</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MensLib</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "         cond  results\n0    Feminism        6\n1  MensRights        3\n2     MensLib        0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cond</th>\n      <th>results</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Feminism</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MensRights</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MensLib</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 By entire comment\n",
    "\n",
    "To calculate the significance for an entire comment we summed the entropy for all the sentences that comprised the comment for each trial number in the data. We then repeated the same testing procedure as performed for the sentence level analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "comment_H = [total_H[_ids['commentId'].isin([c]).values].sum(axis=0).unsqueeze(0) for c in _ids['commentId'].unique()]\n",
    "comment_H = torch.cat(comment_H,dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([103, 3, 200])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_H.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind as ttest\n",
    "\n",
    "pvalue, statistic = [], []\n",
    "for i in range(comment_H.shape[0]):\n",
    "    r = [\n",
    "        ttest(\n",
    "            comment_H[i, 2][~comment_H[i, 2].isnan()],\n",
    "            comment_H[i, j][~comment_H[i, j].isnan()]\n",
    "        ) for j in range(comment_H.shape[1])]\n",
    "    pvalue += [np.array([ri.pvalue for ri in r])]\n",
    "    statistic += [np.array([ri.statistic for ri in r])]\n",
    "\n",
    "pvalue, statistic = np.array(pvalue), np.array(statistic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "minima = [\n",
    "    torch.cat(\n",
    "        [\n",
    "            comment_H[i,j][~comment_H[i,j].isnan()].mean(axis=-1).view(1,-1) for j in range(len(groups))\n",
    "        ],\n",
    "        dim=-1\n",
    "    ) for i in range(comment_H.shape[0])\n",
    "]\n",
    "minima = torch.cat(minima, dim=0).argmin(dim=-1)\n",
    "pct_data, confusion_data, means_data = [], [], []\n",
    "\n",
    "for i, g in enumerate(groups):\n",
    "\n",
    "    p_res = (pvalue[:,i] < .025)\n",
    "    mu_res = (statistic[:,i] < 0)\n",
    "    res =  p_res & mu_res\n",
    "\n",
    "    pct_data += [res.mean(axis=0)]\n",
    "    confusion_data += [(p_res & (minima==i).numpy()).sum(axis=0)]\n",
    "    means_data += [mu_res.mean(axis=0)]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['cond'] = groups\n",
    "results['results'] = np.array(pct_data)\n",
    "\n",
    "mean_results = pd.DataFrame()\n",
    "mean_results['cond'] = groups\n",
    "mean_results['results'] = np.array(means_data)\n",
    "\n",
    "confusion = pd.DataFrame()\n",
    "confusion['cond'] = groups\n",
    "confusion['results'] = np.array(confusion_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "         cond   results\n0    Feminism  0.970874\n1  MensRights  0.980583\n2     MensLib  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cond</th>\n      <th>results</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Feminism</td>\n      <td>0.970874</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MensRights</td>\n      <td>0.980583</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MensLib</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "         cond   results\n0    Feminism  0.980583\n1  MensRights  0.990291\n2     MensLib  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cond</th>\n      <th>results</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Feminism</td>\n      <td>0.980583</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MensRights</td>\n      <td>0.990291</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MensLib</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "         cond  results\n0    Feminism        2\n1  MensRights        0\n2     MensLib        0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cond</th>\n      <th>results</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Feminism</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MensRights</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MensLib</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Analysis of Texts in Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "__ids = _ids.drop_duplicates(subset=['commentId']).copy()\n",
    "__ids.index = range(len(__ids))\n",
    "\n",
    "texts = pd.read_table(\"/Volumes/ROY/comp_ling/datasci/intergroupEntropy/data/redditany/corpus_with_author_data.tsv\", lineterminator='\\n')\n",
    "texts = texts.loc[~texts['body'].isna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we look at the confused sentences for MensLib -> Feminism"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "               author   subId commentId  \\\n25159        pcapdata  une854   i894prn   \n25160        pcapdata  une854   i894prn   \n25238  ladybadcrumble  une854   i88mz31   \n25239  ladybadcrumble  une854   i88mz31   \n25240  ladybadcrumble  une854   i88mz31   \n\n                                                    body  \n25159                                            i agree  \n25160   there’s a meme phrase criticizing that approa...  \n25238                                       oh seriously  \n25239                                         that rules  \n25240  i reported someone for that once and never hea...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>subId</th>\n      <th>commentId</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25159</th>\n      <td>pcapdata</td>\n      <td>une854</td>\n      <td>i894prn</td>\n      <td>i agree</td>\n    </tr>\n    <tr>\n      <th>25160</th>\n      <td>pcapdata</td>\n      <td>une854</td>\n      <td>i894prn</td>\n      <td>there’s a meme phrase criticizing that approa...</td>\n    </tr>\n    <tr>\n      <th>25238</th>\n      <td>ladybadcrumble</td>\n      <td>une854</td>\n      <td>i88mz31</td>\n      <td>oh seriously</td>\n    </tr>\n    <tr>\n      <th>25239</th>\n      <td>ladybadcrumble</td>\n      <td>une854</td>\n      <td>i88mz31</td>\n      <td>that rules</td>\n    </tr>\n    <tr>\n      <th>25240</th>\n      <td>ladybadcrumble</td>\n      <td>une854</td>\n      <td>i88mz31</td>\n      <td>i reported someone for that once and never hea...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confused_indexes = __ids['commentId'].loc[(pvalue[:,0] < .025) & (minima == 0).numpy()]\n",
    "\n",
    "texts[['author','subId','commentId','body']].loc[texts['commentId'].isin(confused_indexes)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [author, subId, commentId, body]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>subId</th>\n      <th>commentId</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confused_indexes = __ids['commentId'].loc[(pvalue[:,1] < .025) & (minima == 1).numpy()]\n",
    "\n",
    "texts[['author','subId','commentId','body']].loc[texts['commentId'].isin(confused_indexes)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4 Comparison of MensLib from Feminism vs. MensLib from MensRights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "pvalue, statistic = [], []\n",
    "for i in range(comment_H.shape[0]):\n",
    "    r = [\n",
    "        ttest(\n",
    "            comment_H[i, 0][~comment_H[i, 0].isnan()],\n",
    "            comment_H[i, 1][~comment_H[i, 1].isnan()]\n",
    "        )\n",
    "    ]\n",
    "    pvalue += [np.array([ri.pvalue for ri in r])]\n",
    "    statistic += [np.array([ri.statistic for ri in r])]\n",
    "\n",
    "pvalue, statistic = np.array(pvalue), np.array(statistic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.array(['Feminism', 'MensRights']).reshape(-1,1), columns=['group'])\n",
    "\n",
    "results['% similarity'] = [((pvalue < .025) & (statistic < 0)).mean(), ((pvalue < .025) & (statistic > 0)).mean()]\n",
    "\n",
    "results['% inconclusive'] = [((pvalue > .025) & (statistic < 0)).mean(), ((pvalue > .025) & (statistic > 0)).mean()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "        group  % similarity  % inconclusive\n0    Feminism      0.679612        0.116505\n1  MensRights      0.126214        0.077670",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>% similarity</th>\n      <th>% inconclusive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Feminism</td>\n      <td>0.679612</td>\n      <td>0.116505</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MensRights</td>\n      <td>0.126214</td>\n      <td>0.077670</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conclusions\n",
    "\n",
    "The results are interesting. I'll break them up by comparison to each other subreddit here.\n",
    "\n",
    "[_**r/Feminism**_] How much can you learn about comments from r/MensLib when reading comments made to r/Feminism when compared to reading comments from the same subreddit? It turns out, not nearly as much as one might initially think. At a sentence level 96.5\\% of sentences from r/MensLib have lower entropy when compared to other comments from r/MensLib compared to comments from r/Feminism. In 98.5\\% of cases there is, at a minimum, a lower mean for entropy comparing sentences from r/MensLib to other comments from r/MensLib as opposed to comments from r/Feminism. This discrepency is a little wider when looking at comments as opposed to just sentences. 97.1\\% of sentences from r/MensLib have lower entropy when compared to other comments from r/MensLib compared to comments from r/Feminism. In 98.1\\% of cases there is, at a minimum, a lower mean for entropy comparing sentences from r/MensLib to other comments from r/MensLib as opposed to comments from r/Feminism.\n",
    "\n",
    "[_**r/MensRights**_] How much can you learn about comments from r/MensLib when reading comments made to r/MensRights when compared to reading comments from the same subreddit? Much like when compared to r/MensRights, very little. At a sentence level 97.0\\% of sentences from r/MensLib have lower entropy when compared to other comments from r/MensLib compared to comments from r/MensRights. In 97.8\\% of cases there is, at a minimum, a lower mean for entropy comparing sentences from r/MensLib to other comments from r/MensLib as opposed to comments from r/MensRights. This discrepency is a little wider when looking at comments as opposed to just sentences. 98.1\\% of sentences from r/MensLib have lower entropy when compared to other comments from r/MensLib compared to comments from r/MensRights. In 99.0\\% of cases there is, at a minimum, a lower mean for entropy comparing sentences from r/MensLib to other comments from r/MensLib as opposed to comments from r/MensRights.\n",
    "\n",
    "[_**Confusion matrix**_] We now ask how often is it that a message from r/MensLib might be confused for one from either r/Feminism or r/MensRights (i.e. $p<.025$ and the mean for entropy from the outgroup is lower than the mean for the entropy in the ingroup).\n",
    "\n",
    "At the sentence level, in 6 cases utterances made by members of r/MensLib have statistically significant, greater similarity with content generated in r/Feminism and in 3 cases utterances made by members of r/MensLib have statistically significant, greater similarity with content generated in r/MensRights.\n",
    "\n",
    "At the comment levels, in 2 cases utterances made by members of r/MensLib have statistically significant, greater similarity with content generated in r/Feminism. No instances in which an entire comment had statistically significant, greater similarity with content generated in r/MensRights were found.\n",
    "\n",
    "[_**Similarity to r/Feminism vs. r/MensRights**_] We compared the regeneration of comments from r/MensLib using samples from the outgroup r/Feminism (outgroup 1) to using samples from the outgroup r/MensRights (outgroup 2). In 67.9\\% of cases, entropy for reconstructing messages from r/MensLib from samples pulled from outgroup 1 are statistically significant and lower than when reconstructing the same messages from samples pulled from outgroup 2. 11.6\\% of cases are inconclusive (statistical significance was not reached). In 12.6\\% of cases, entropy for reconstructing messages from r/MensLib from samples pulled from outgroup 2 are statistically significant and lower than when reconstructing the same messages from samples pulled from outgroup 1. 7.8\\% of cases are inconclusive (statistical significance was not reached). We conclude that whilst messages from r/MensLib show signs of high intragroup convergence, there is still greater similarity overall with other Feminist groups than there are with other groups from the manosphere.\n",
    "\n",
    "\n",
    "Bear in mind that there is, at the comment level, no cases in which one could confuse a comment from r/MensLib with a comment from r/MensRights. There are two instances however in which one could confuse a comment a from r/MensRights with a comment for r/Feminism outright.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### References\n",
    "\n",
    "Adams, A., Miles, J., Dunbar, N. E., & Giles, H. (2018). Communication accommodation in text messages: Exploring liking, power, and sex as predictors of textisms. The Journal of Social Psychology, 158(4), 474–490. https://doi.org/10.1080/00224545.2017.1421895\n",
    "\n",
    "Dale, R., Duran, N. D., & Coco, M. (2018). Dynamic Natural Language Processing with Recurrence Quantification Analysis. ArXiv:1803.07136 [Cs]. http://arxiv.org/abs/1803.07136\n",
    "\n",
    "de Vries, W., van Cranenburgh, A., & Nissim, M. (2020). What’s so special about BERT’s layers? A closer look at the NLP pipeline in monolingual and multilingual models. Findings of the Association for Computational Linguistics: EMNLP 2020, 4339–4350\n",
    "\n",
    "Palomares, N., Giles, H., Soliz, J., & Gallois, C. (2016). Intergroup Accommodation, Social Categories, and Identities. In H. Giles (Ed.), Communication Accomodation Theory (p. 232).\n",
    "\n",
    "Rosen, Z. (2022). A BERT’s eye view: A “big-data” framework for assessing language convergence and accommodation in large, many-to-many settings. Journal of Language and Social Psychology, 0261927X2210811."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}