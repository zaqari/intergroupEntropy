{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Word Vectors for Each Utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import regex as re\n",
    "from datetime import datetime as dt\n",
    "from mod.LM.RoBERTa import RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Importing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = dt.now()\n",
    "PATH = 'data/'\n",
    "dataset = 'scrape_data/reddit-data.tsv'\n",
    "output_name = 'vecs/reddit-vecs.tsv'\n",
    "\n",
    "\n",
    "df = pd.read_table(PATH + dataset, lineterminator='\\n')\n",
    "print('pre-dropping of irrelevant data', len(df))\n",
    "\n",
    "df = df.drop_duplicates(subset=['author', 'body'])\n",
    "df = df.loc[~df['body'].isna()]\n",
    "df.index=range(len(df))\n",
    "\n",
    "print(list(df))\n",
    "print(PATH, len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Setting up model components"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "level = [8,-1]\n",
    "mod = RoBERTa(device='cuda', special_tokens=False, layers=level)\n",
    "mod.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Vectorizing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're going to stream the data. So to start, we set up a file that we'll save the data to."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meta_data_cols = ['subreddit','subId', 'sub_time', 'commentId', 'likes', 'time', 'author']\n",
    "\n",
    "data = pd.DataFrame(columns=['_id'] + meta_data_cols + ['token', 'vec'])\n",
    "data.to_csv(PATH+output_name, index=False, encoding='utf-8', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then we'll use our word vector model to generate embeddings and save them to the appropriate directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ct = 0\n",
    "with torch.no_grad():\n",
    "    for k in df.index:\n",
    "        text = df['body'].loc[k]\n",
    "        meta_data = df[meta_data_cols].loc[k].values.tolist()\n",
    "        ct+=1\n",
    "\n",
    "        try:\n",
    "            w, tokens = mod._tokenize(str(text).replace('\\n', ' '))\n",
    "            sel = ((tokens == np.array(['.', '!', '?', ',', '...', ':', ';', '. . .']).reshape(-1, 1)).sum(axis=0) == 0)\n",
    "            vecs = mod.E(torch.LongTensor(w).view(-1)[sel])\n",
    "            update = [[k] + meta_data + [tokens[sel][i], str(vec.cpu().view(-1).tolist())] for\n",
    "                      i, vec in enumerate(vecs)]\n",
    "            update = pd.DataFrame(np.array(update, dtype='object').reshape(-1, len(list(data))), columns=list(data))\n",
    "            update.to_csv(PATH + output_name, index=False, encoding='utf-8', header=False, mode='a', sep='\\t')\n",
    "\n",
    "            if len(vecs) == 0:\n",
    "                ct -= 1\n",
    "\n",
    "        except ValueError:\n",
    "            ct -= 1\n",
    "\n",
    "        except IndexError:\n",
    "            ct -= 1\n",
    "\n",
    "        except RuntimeError:\n",
    "            ct -= 1\n",
    "\n",
    "        except AttributeError:\n",
    "            ct -= 1\n",
    "\n",
    "print('total passable items ({}/{}) in t(s)={}'.format(ct, len(df), dt.now()-start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}